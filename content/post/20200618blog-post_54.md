---
title: '文書分類問題の応用'
date: 2020-06-18T06:42:00.008+09:00
draft: false
aliases: [ "/2020/06/blog-post_54.html" ]
tags : [技術系,自然言語処理,技術,文書分類]
---
## 文書分類問題の応用[](#文書分類問題の応用 "文書分類問題の応用")


機械学習について勉強したけど、その使い道が分からん！ってなってないですか？

勉強するときに強く意識してないと見落としがちですが、どうやって使うんだろう、とアンテナを常日頃から張らないと使い道が分からなくなります。

使われてこその道具ですから、新しく手に入れた道具だての使い道をメモしておきます。


## 文書分類問題の適用範囲[](#文書分類問題の適用範囲 "文書分類問題の適用範囲")


自然言語処理の文書分類について勉強をしたなら以下のことが出来るようになっています。

*   スパムメール検出
*   ニュースのトピック分類
*   重要箇所抽出
*   文書要約
*   ユーザーへのレコメンド
*   クラスタリング
*   感情分析など

意外と活用の範囲は広そうですね？

## 文書分類問題とは[](#文書分類問題とは "文書分類問題とは")


一つの文書に対して、一つ以上のラベルを付けることです。機械学習ではラベルを予測するモデルを作ります。

ここで文書は短いものは単語、長いものはニュース記事までと、あまり長さは関係ありません。

ラベルとしては、重要かどうか(バイナリ)、トピック、感情(マルチクラス、マルチラベル)などを付けます。

教師有りの手法と教師無しの手法があります。

### 教師有り[](#教師有り "教師有り")

教師有りの場合はラベルを人間が用意する必要があります。

クラウドソーシングを利用したアノテーション作業を行ったり、SNSのタグやECサイトのレビューなどを収集したりします。

この場合、自力では十分な量のデータを用意できないこともままあります。そのため、機械学習の手法は有効でしょう。

### 教師無し[](#教師無し "教師無し")

教師無しは文書のデータだけがあればいいのでデータの準備が楽です。

ウィキペディアのデータを流用することなどが挙げられます。

### 特徴量[](#特徴量 "特徴量")

文書から特徴量を抽出する必要があります。

特徴量はTF-IDFや分散表現が用いられます。

最近の研究(2020年時点)では深層学習がおもなトピックです。

得られた特徴量を元に、教師有りの場合は、SVMなどの機械学習の手法を用いて分類することができます。

## 実際の利用例[](#実際の利用例 "実際の利用例")


実際の利用方法は以下のリンクにメモしています。

- [Universal Sentence Encoder の使い方メモ]({{<ref "post/universal-sentence-encoder.md">}})
- [日本語Wikipediaで学習したBERTが公開されたので使い方のメモ]({{<ref "post/wikipediabert.md">}})
- [Google colaboratory を使ってWord2Vecの仕組みからモデルの学習まで]({{<ref "post/20200615google-colaboratory-word2vec.md">}})
- [Fasttext で文書分類問題までやったった]({{<ref "post/fasttext.md">}})
- [文書分類問題を解くモデルを提供するNeuralClassifier の使い方メモ]({{<ref "post/neuralclassifier.md">}})
- [Sentence BERT 日本語モデルの学習 メモ]({{<ref "post/20210203SBERT.md">}})
- [分散表現の利用法 バギングによるクラス分類や汎化性能についてのメモ]({{<ref "/post/20210204classifier.md">}})
